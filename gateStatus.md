GateStatus 관련 포트폴리오 면접 질문

1. 프로젝트 소개 2030 젊은 세대의 투표 독려 및 정치인의 공약과 발언을 쉽게 찾게 도와주는 플랫폼입니다. ChatGPT를 사용해 AI 기반 발언 및 기사를 참조해 팩트체크를 하는 기능을 갖추고 국회 공개 API와 OpenAI, Naver 뉴스 를 연동했습니다 
2. 프로젝트 동기  
3. 멀티 데이터베이스 설계 - PostgreSQL과 MongoDB를 함께 사용한 이유는? PostgreSQL로 정치인의 기본 정보, 법률, 투표 기록만 담당했습니다 변하지않는 공식 데이터와 관계형 구조를 위해서 였고 MongoDB는 "OpenAPI로 수집하는 대용량 발언 데이터를 효율적으로 저장하고, 뉴스와 교차 분석해서 AI 팩트체크 점수를 매기는 시스템이다보니 MongoDB가 필수였습니다. 특히 정치인 발언 텍스트 검색 성능과 AI 분석 결과를 유연하게 저장할 수 있어서 선택했습니다." 
4. 도메인 구조를 어떻게 설계했나요 ? DDD 도메인 주도 설계를 통해 도메인 별로 분리하고, 각 도메인 내에서 레이어드 아키텍쳐로 기술적 관심사를 분리했습니다 그리고 기능별 패키징으로 응집도를 높였습니다. 
5. Redis를 어떻게 사용했나요 ? Redis를 세 가지 용도로 활용했습니다. 첫째, 세션 관리로 사용자 로그인 상태를 2시간 TTL로 저장해서 서버 재시작 시에도 로그인이 유지됩니다. 둘째, 자주 조회되는 정치인 목록과 이슈 정보를 캐싱해서 DB 조회 시간을 500ms에서 20ms로 단축했습니다. 셋째, 데이터 특성에 따라 TTL을 차등 적용했는데, 거의 변하지 않는 정당별 정치인은 1시간, 상대적으로 자주 바뀌는 인기 정치인은 30분으로 설정했습니다. 
6. OpenAI를 어떻게 활용했나요? 주로 OpenAI를 통해 국회에서 제공하는 기사 및 인터뷰 혹은 네이버 기사의 정보를 받아 연설/인터뷰/보도자료를 분류하고 선택한 정치인의 발언에 팩트체크를 점수화시키고 핵심 토픽을 자동 추출해 키워드를 추출하는 방향으로 활용했습니다. 
7. AI API호출 비용과 성능을 어떻게 최적화했나요 ? 현재는 AI API를 개별 호출하는 방식이라 최적화 여지가 많습니다. 향후 개선 계획으로는 첫째, Redis를 활용한 AI 분석 결과 캐싱으로 중복 호출을 방지하고, 둘째, 50자 미만 텍스트는 AI 호출 없이 기본값을 반환하는 조건부 호출을 적용할 예정입니다. 셋째, 여러 발언을 모아서 배치 처리하여 API 호출 횟수를 줄이고, 넷째, API 실패 시 로컬 분석으로 fallback하는 에러 핸들링을 강화하겠습니다. 이렇게 하면 AI 비용을 60-70% 절약하면서 응답 속도도 2-3배 개선할 수 있을 것으로 예상합니다 
8. Kafka와 RabbitMQ를 함께 사용한 이유는 ? 초기 설계에서는 Kafka와 RabbitMQ를 모두 사용할 계획이었지만, 실제 구현 과정에서 Kafka는 필요하지 않다고 판단해서 제거했습니다. RabbitMQ는 법안 동기화 작업에만 사용했는데, 솔직히 이 정도 규모에서는 오버엔지니어링이었다고 생각합니다. 하지만 큐 기반 비동기 처리 패턴을 경험할 수 있었고, 다음에는 기술 선택을 더 신중하게 하겠습니다.  
9. 국회 API 연동에서 어려웠던 점은?  **"가장 어려웠던 건 XML 파싱이었습니다. 국회 API 응답 구조가 매우 복잡하고, 'nwvrqwxyaytdsfvhu' 같은 의미 없는 키 이름 때문에 시행착오가 많았어요. 그리고 받아온 데이터에 HTML 엔티티가 섞여 있어서 별도 디코딩 로직을 만들어야 했고, XXE 공격 방지를 위한 보안 설정도 추가해야 했습니다. 페이징 처리도 복잡했는데, 전체 데이터를 한 번에 못 가져와서 여러 번 API 호출해야 했거든요. Rate Limiting은 실제로는 구현하지 않았는데, 다음에는 API 호출 간격 조절도 고려해야겠다고 생각했습니다."** 
10. 성능 개선을 위해 어떤 노력을 했나요 ? 세 가지 성능 최적화를 했습니다.  첫째, Redis 캐싱으로 자주 조회되는 정치인 정보의 응답 시간을 500ms에서 20ms로 단축했습니다.  둘째, MongoDB에 복합 인덱스와 텍스트 인덱스를 적용해서 발언 검색 성능을 개선했습니다.  셋째, 대용량 데이터 처리 시 50개씩 배치로 나눠서 메모리 사용량을 최적화했습니다.  
11. 사용자가 급증할땐 어떻게 대응할건가요 ?  
12. Kubernetes를 사용한 이유와 경험은 ?
13. 서비스 모니터링은 어떻게 하고 있나요 ?
14. 보안을 어떻게 구현했나요 ? Spring Security 기반으로 다층 보안을 구현했습니다. 첫째, 인증은 HTTP Basic + 세션 기반으로 하고 BCrypt 암호화를 사용했어요. 둘째, CORS는 프론트엔드 도메인만 허용하도록 제한했고, CSRF는 API는 비활성화하되 웹페이지는 보호하도록 설정했습니다. 셋째, XSS 방지를 위해 보안 헤더를 설정하고 입력값에서 스크립트 태그를 제거하는 필터를 추가했어요. 넷째, SQL 인젝션 방지를 위해 입력값 검증을 강화하고 위험한 키워드를 차단합니다. 
15. 가장 어려웠던 기술적 문제와 해결 방법은 ?  
16. 멀티 데이터베이스 환경에서 어떻게 데이터 일관성을 보장했나요?  
17. 정치인 비교 분석 기능은 어떻게 구현했나요 ? 구조적으로는 ComparisonService가 전체 프로세스를 조율하고, DataService가 PostgreSQL과 MongoDB에서 데이터를 수집하며, ResultBuilder가 결과를 조합하는 책임 분리 구조로 설계했습니다. 비즈니스 로직 측면에서는 발언, 투표, 법안 3개 차원의 데이터를 각각 분석하고, 사용자가 원하는 비교 타입만 선택적으로 처리할 수 있도록 했어요. 성능 최적화를 위해서는 배치 쿼리로 N+1 문제를 해결하고, 개별 정치인 처리 실패가 전체에 영향주지 않도록 예외 처리를 탄탄하게 했습니다. 그리고 ID/이름/혼합 입력 방식을 모두 지원해서 사용자 편의성도 고려했습니다." 
18. RESTful API 설계 시 고려한 점은?  
19. 코드 품질을 어떻게 관리했나요 ?  
20. 코드를 개선한 경험이 있나요?  
21. 이 프로젝트를 더 발전시킨다면?

* 예상 꼬리 질문:
* "그럼 MongoDB 대신 PostgreSQL만 써도 되지 않았을까요?"
* "OpenAI API 비용이 많이 나올 텐데 어떻게 관리했나요?"
* "사용자가 100만명이 되면 어떻게 대응할 건가요?"
* "보안 취약점은 없나요?"
* "테스트는 어떻게 작성했나요?"

